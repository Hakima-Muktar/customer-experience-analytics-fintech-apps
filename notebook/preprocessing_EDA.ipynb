{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b13a9c3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\u001b[34;43m__file__\u001b[39;49m))))\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Import numpy for numerical operations (though mostly used implicitly by pandas here)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "import pandas as pd\n",
    "# Import numpy for numerical operations (though mostly used implicitly by pandas here)\n",
    "import numpy as np\n",
    "# Import datetime class from datetime module to handle date and time objects\n",
    "from datetime import datetime\n",
    "# Import re module for regular expression operations (used for text cleaning)\n",
    "import re\n",
    "# Import DATA_PATHS dictionary from the local config module\n",
    "from config import DATA_PATHS\n",
    "\n",
    "class ReviewPreprocessor:\n",
    "    \"\"\"Preprocessor class for review data\"\"\"\n",
    "\n",
    "    def __init__(self, input_path=None, output_path=None):\n",
    "        \"\"\"\n",
    "        Initialize preprocessor\n",
    "\n",
    "        Args:\n",
    "            input_path (str): Path to raw reviews CSV\n",
    "            output_path (str): Path to save processed reviews\n",
    "        \"\"\"\n",
    "        # Set the input path: use the provided argument, or default to DATA_PATHS['raw_reviews'] from config\n",
    "        self.input_path = input_path or DATA_PATHS['raw_reviews']\n",
    "        # Set the output path: use the provided argument, or default to DATA_PATHS['processed_reviews'] from config\n",
    "        self.output_path = output_path or DATA_PATHS['processed_reviews']\n",
    "        # Initialize an empty DataFrame attribute to hold our data\n",
    "        self.df = None\n",
    "        # Initialize a dictionary to keep track of processing statistics (counts, errors, etc.)\n",
    "        self.stats = {}\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load raw reviews data\"\"\"\n",
    "        # Print a message indicating that data loading has started\n",
    "        print(\"Loading raw data...\")\n",
    "        try:\n",
    "            # Read the CSV file at self.input_path into a pandas DataFrame\n",
    "            self.df = pd.read_csv(self.input_path)\n",
    "            # Print the number of records loaded\n",
    "            print(f\"Loaded {len(self.df)} reviews\")\n",
    "            # Record the initial number of records in our stats dictionary\n",
    "            self.stats['original_count'] = len(self.df)\n",
    "            # Return True to indicate success\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            # Handle the specific error where the file does not exist\n",
    "            print(f\"ERROR: File not found: {self.input_path}\")\n",
    "            # Return False to indicate failure\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            # Handle any other general errors that occur during loading\n",
    "            print(f\"ERROR: Failed to load data: {str(e)}\")\n",
    "            # Return False to indicate failure\n",
    "            return False\n",
    "\n",
    "    def check_missing_data(self):\n",
    "        \"\"\"Check for missing data\"\"\"\n",
    "        # Print a header for this step [1/6]\n",
    "        print(\"\\n[1/6] Checking for missing data...\")\n",
    "\n",
    "        # Calculate the count of missing (null) values for each column\n",
    "        missing = self.df.isnull().sum()\n",
    "        # Calculate the percentage of missing values for each column\n",
    "        missing_pct = (missing / len(self.df)) * 100\n",
    "\n",
    "        # Print the section header\n",
    "        print(\"\\nMissing values:\")\n",
    "        # Loop through each column name in the index of the 'missing' series\n",
    "        for col in missing.index:\n",
    "            # If the column has at least one missing value\n",
    "            if missing[col] > 0:\n",
    "                # Print the column name, count of missing values, and percentage\n",
    "                print(f\"  {col}: {missing[col]} ({missing_pct[col]:.2f}%)\")\n",
    "\n",
    "        # Store the dictionary of missing counts in our stats for reporting later\n",
    "        self.stats['missing_before'] = missing.to_dict()\n",
    "\n",
    "        # Define a list of columns that are absolutely required for our analysis\n",
    "        critical_cols = ['review_text', 'rating', 'bank_name']\n",
    "        # Calculate missing values just for these critical columns\n",
    "        missing_critical = self.df[critical_cols].isnull().sum()\n",
    "\n",
    "        # If there are any missing values in critical columns\n",
    "        if missing_critical.sum() > 0:\n",
    "            # Print a warning message\n",
    "            print(\"\\nWARNING: Missing values in critical columns:\")\n",
    "            # Print the counts of missing values for the critical columns that have them\n",
    "            print(missing_critical[missing_critical > 0])\n",
    "\n",
    "    def handle_missing_values(self):\n",
    "        \"\"\"Handle missing values\"\"\"\n",
    "        # Print a header for this step [2/6]\n",
    "        print(\"\\n[2/6] Handling missing values...\")\n",
    "\n",
    "        # Define the critical columns again\n",
    "        critical_cols = ['review_text', 'rating', 'bank_name']\n",
    "        # Store the count before dropping rows\n",
    "        before_count = len(self.df)\n",
    "        # Drop any rows that have missing values (NaN) in the critical columns\n",
    "        self.df = self.df.dropna(subset=critical_cols)\n",
    "        # Calculate how many rows were removed\n",
    "        removed = before_count - len(self.df)\n",
    "\n",
    "        # If any rows were removed, print a message\n",
    "        if removed > 0:\n",
    "            print(f\"Removed {removed} rows with missing critical values\")\n",
    "\n",
    "        # For the 'user_name' column, fill missing values with the string 'Anonymous'\n",
    "        self.df['user_name'] = self.df['user_name'].fillna('Anonymous')\n",
    "        # For the 'thumbs_up' column, fill missing values with 0\n",
    "        self.df['thumbs_up'] = self.df['thumbs_up'].fillna(0)\n",
    "        # For the 'reply_content' column, fill missing values with an empty string\n",
    "        self.df['reply_content'] = self.df['reply_content'].fillna('')\n",
    "\n",
    "        # Record the number of rows removed due to missing critical data\n",
    "        self.stats['rows_removed_missing'] = removed\n",
    "        # Record the new total count in stats\n",
    "        self.stats['count_after_missing'] = len(self.df)\n",
    "\n",
    "    def normalize_dates(self):\n",
    "        \"\"\"Normalize date formats to YYYY-MM-DD\"\"\"\n",
    "        # Print a header for this step [3/6]\n",
    "        print(\"\\n[3/6] Normalizing dates...\")\n",
    "\n",
    "        try:\n",
    "            # Convert the 'review_date' column to pandas datetime objects\n",
    "            # This handles various string formats automatically\n",
    "            self.df['review_date'] = pd.to_datetime(self.df['review_date'])\n",
    "\n",
    "            # Convert the datetime objects to just date objects (YYYY-MM-DD), removing time info\n",
    "            self.df['review_date'] = self.df['review_date'].dt.date\n",
    "\n",
    "            # Extract the year from the date and create a new 'review_year' column\n",
    "            self.df['review_year'] = pd.to_datetime(self.df['review_date']).dt.year\n",
    "            # Extract the month from the date and create a new 'review_month' column\n",
    "            self.df['review_month'] = pd.to_datetime(self.df['review_date']).dt.month\n",
    "\n",
    "            # Print the range of dates found in the data (minimum and maximum)\n",
    "            print(f\"Date range: {self.df['review_date'].min()} to {self.df['review_date'].max()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle errors if date conversion fails\n",
    "            print(f\"WARNING: Error normalizing dates: {str(e)}\")\n",
    "\n",
    "    def clean_text(self):\n",
    "        \"\"\"Clean review text\"\"\"\n",
    "        # Print a header for this step [4/6]\n",
    "        print(\"\\n[4/6] Cleaning text...\")\n",
    "\n",
    "        def clean_review_text(text):\n",
    "            \"\"\"Inner function to clean individual review text strings\"\"\"\n",
    "            # If the text is NaN (missing) or empty string, return empty string\n",
    "            if pd.isna(text) or text == '':\n",
    "                return ''\n",
    "\n",
    "            # Convert the input to a string type (safety check)\n",
    "            text = str(text)\n",
    "\n",
    "            # Use regex to replace multiple whitespace characters (spaces, tabs, newlines) with a single space\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "            # Remove leading and trailing whitespace from the string\n",
    "            text = text.strip()\n",
    "\n",
    "            # Return the cleaned text\n",
    "            return text\n",
    "\n",
    "        # Apply the 'clean_review_text' function to every element in the 'review_text' column\n",
    "        self.df['review_text'] = self.df['review_text'].apply(clean_review_text)\n",
    "\n",
    "        # Store the count before removing empty reviews\n",
    "        before_count = len(self.df)\n",
    "        # Keep only rows where the length of 'review_text' is greater than 0\n",
    "        self.df = self.df[self.df['review_text'].str.len() > 0]\n",
    "        # Calculate how many empty reviews were removed\n",
    "        removed = before_count - len(self.df)\n",
    "\n",
    "        # If rows were removed, print a message\n",
    "        if removed > 0:\n",
    "            print(f\"Removed {removed} reviews with empty text\")\n",
    "\n",
    "        # Create a new column 'text_length' containing the character count of the review text\n",
    "        self.df['text_length'] = self.df['review_text'].str.len()\n",
    "\n",
    "        # Record statistics about text cleaning\n",
    "        self.stats['empty_reviews_removed'] = removed\n",
    "        self.stats['count_after_cleaning'] = len(self.df)\n",
    "\n",
    "    def validate_ratings(self):\n",
    "        \"\"\"Validate rating values (should be 1-5)\"\"\"\n",
    "        # Print a header for this step [5/6]\n",
    "        print(\"\\n[5/6] Validating ratings...\")\n",
    "\n",
    "        # Find rows where 'rating' is less than 1 OR greater than 5\n",
    "        invalid = self.df[(self.df['rating'] < 1) | (self.df['rating'] > 5)]\n",
    "\n",
    "        # If there are any invalid ratings\n",
    "        if len(invalid) > 0:\n",
    "            # Print a warning with the count of invalid ratings\n",
    "            print(f\"WARNING: Found {len(invalid)} reviews with invalid ratings\")\n",
    "            # Filter the DataFrame to keep only rows where rating is between 1 and 5 (inclusive)\n",
    "            self.df = self.df[(self.df['rating'] >= 1) & (self.df['rating'] <= 5)]\n",
    "        else:\n",
    "            # If all ratings are valid, print a confirmation\n",
    "            print(\"All ratings are valid (1-5)\")\n",
    "\n",
    "        # Record the number of invalid ratings removed\n",
    "        self.stats['invalid_ratings_removed'] = len(invalid)\n",
    "\n",
    "    def prepare_final_output(self):\n",
    "        \"\"\"Prepare final output format\"\"\"\n",
    "        # Print a header for this step [6/6]\n",
    "        print(\"\\n[6/6] Preparing final output...\")\n",
    "\n",
    "        # Define a list of columns in the desired order for the final output file\n",
    "        output_columns = [\n",
    "            'review_id',\n",
    "            'review_text',\n",
    "            'rating',\n",
    "            'review_date',\n",
    "            'review_year',\n",
    "            'review_month',\n",
    "            'bank_code',\n",
    "            'bank_name',\n",
    "            'user_name',\n",
    "            'thumbs_up',\n",
    "            'text_length',\n",
    "            'source'\n",
    "        ]\n",
    "\n",
    "        # Filter the list to include only columns that actually exist in our DataFrame\n",
    "        # This prevents errors if a column was missed in previous steps\n",
    "        output_columns = [col for col in output_columns if col in self.df.columns]\n",
    "        # Reorder the DataFrame columns according to our list\n",
    "        self.df = self.df[output_columns]\n",
    "\n",
    "        # Sort the DataFrame first by 'bank_code' (ascending) and then by 'review_date' (descending/newest first)\n",
    "        self.df = self.df.sort_values(['bank_code', 'review_date'], ascending=[True, False])\n",
    "\n",
    "        # Reset the index of the DataFrame so it starts from 0 to N-1 cleanly\n",
    "        # drop=True prevents the old index from being added as a new column\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "\n",
    "        # Print the final count of reviews\n",
    "        print(f\"Final dataset: {len(self.df)} reviews\")\n",
    "\n",
    "    def save_data(self):\n",
    "        \"\"\"Save processed data\"\"\"\n",
    "        # Print a message indicating saving has started\n",
    "        print(\"\\nSaving processed data...\")\n",
    "\n",
    "        try:\n",
    "            # Create the directory for the output file if it doesn't already exist\n",
    "            # os.path.dirname gets the folder part of the file path\n",
    "            os.makedirs(os.path.dirname(self.output_path), exist_ok=True)\n",
    "\n",
    "            # Write the DataFrame to a CSV file at self.output_path\n",
    "            # index=False prevents writing the row numbers (0, 1, 2...) to the file\n",
    "            self.df.to_csv(self.output_path, index=False)\n",
    "            # Print a confirmation message with the path\n",
    "            print(f\"Data saved to: {self.output_path}\")\n",
    "\n",
    "            # Record the final count in stats\n",
    "            self.stats['final_count'] = len(self.df)\n",
    "            # Return True to indicate success\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any errors during saving\n",
    "            print(f\"ERROR: Failed to save data: {str(e)}\")\n",
    "            # Return False to indicate failure\n",
    "            return False\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate preprocessing report\"\"\"\n",
    "        # Print a separator line\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        # Print the report title\n",
    "        print(\"PREPROCESSING REPORT\")\n",
    "        # Print a separator line\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Print various statistics gathered during the process using .get() to avoid errors if key is missing\n",
    "        print(f\"\\nOriginal records: {self.stats.get('original_count', 0)}\")\n",
    "        print(f\"Records with missing critical data: {self.stats.get('rows_removed_missing', 0)}\")\n",
    "        print(f\"Empty reviews removed: {self.stats.get('empty_reviews_removed', 0)}\")\n",
    "        print(f\"Invalid ratings removed: {self.stats.get('invalid_ratings_removed', 0)}\")\n",
    "        print(f\"Final records: {self.stats.get('final_count', 0)}\")\n",
    "\n",
    "        # Calculate data quality percentage metrics\n",
    "        if self.stats.get('original_count', 0) > 0:\n",
    "            # Retention rate = (Final / Original) * 100\n",
    "            # We use .get(..., 1) for denominator to avoid division by zero if original_count is missing\n",
    "            retention_rate = (self.stats.get('final_count', 0) / self.stats.get('original_count', 1)) * 100\n",
    "            # Error rate is the inverse of retention rate\n",
    "            error_rate = 100 - retention_rate\n",
    "            print(f\"\\nData retention rate: {retention_rate:.2f}%\")\n",
    "            print(f\"Data error rate: {error_rate:.2f}%\")\n",
    "\n",
    "            # Assess quality based on error rate thresholds\n",
    "            if error_rate < 5:\n",
    "                print(\"‚úì Data quality: EXCELLENT (<5% errors)\")\n",
    "            elif error_rate < 10:\n",
    "                print(\"‚úì Data quality: GOOD (<10% errors)\")\n",
    "            else:\n",
    "                print(\"‚ö† Data quality: NEEDS ATTENTION (>10% errors)\")\n",
    "\n",
    "        # Print statistics about the reviews per bank\n",
    "        if self.df is not None:\n",
    "            print(\"\\nReviews per bank:\")\n",
    "            # Count occurrences of each unique value in 'bank_name'\n",
    "            bank_counts = self.df['bank_name'].value_counts()\n",
    "            # Loop through the results and print them\n",
    "            for bank, count in bank_counts.items():\n",
    "                print(f\"  {bank}: {count}\")\n",
    "\n",
    "            # Print statistics about rating distribution\n",
    "            print(\"\\nRating distribution:\")\n",
    "            # Count occurrences of each rating, and sort by rating (5 down to 1)\n",
    "            rating_counts = self.df['rating'].value_counts().sort_index(ascending=False)\n",
    "            for rating, count in rating_counts.items():\n",
    "                # Calculate percentage for this rating\n",
    "                pct = (count / len(self.df)) * 100\n",
    "                # Print star representation, count, and percentage\n",
    "                print(f\"  {'‚≠ê' * int(rating)}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "            # Print the full date range of the data\n",
    "            print(f\"\\nDate range: {self.df['review_date'].min()} to {self.df['review_date'].max()}\")\n",
    "\n",
    "            # Print statistics about the length of the review texts\n",
    "            print(f\"\\nText statistics:\")\n",
    "            print(f\"  Average length: {self.df['text_length'].mean():.0f} characters\")\n",
    "            print(f\"  Median length: {self.df['text_length'].median():.0f} characters\")\n",
    "            print(f\"  Min length: {self.df['text_length'].min()}\")\n",
    "            print(f\"  Max length: {self.df['text_length'].max()}\")\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"Run complete preprocessing pipeline\"\"\"\n",
    "        # Print start header\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STARTING DATA PREPROCESSING\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Attempt to load data. If it fails, return False immediately.\n",
    "        if not self.load_data():\n",
    "            return False\n",
    "\n",
    "        # Run each step of the pipeline in sequence\n",
    "        self.check_missing_data()\n",
    "        # self.remove_duplicates() - REMOVED AS REQUESTED\n",
    "        self.handle_missing_values()\n",
    "        self.normalize_dates()\n",
    "        self.clean_text()\n",
    "        self.validate_ratings()\n",
    "        self.prepare_final_output()\n",
    "\n",
    "        # Attempt to save the data. If successful, generate the report.\n",
    "        if self.save_data():\n",
    "            self.generate_report()\n",
    "            return True\n",
    "\n",
    "        # If saving failed, return False\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # Create an instance of the ReviewPreprocessor class\n",
    "    preprocessor = ReviewPreprocessor()\n",
    "    # Run the processing pipeline\n",
    "    success = preprocessor.process()\n",
    "\n",
    "    # Check if the process was successful\n",
    "    if success:\n",
    "        print(\"\\n‚úì Preprocessing completed successfully!\")\n",
    "        # Return the processed DataFrame\n",
    "        return preprocessor.df\n",
    "    else:\n",
    "        print(\"\\n‚úó Preprocessing failed!\")\n",
    "        # Return None to indicate failure\n",
    "        return None\n",
    "\n",
    "\n",
    "# Standard Python check to see if this file is being run directly (not imported)\n",
    "if __name__ == \"__main__\":\n",
    "    # If run directly, execute the main function\n",
    "    processed_df = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dff5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting Scraper...\")\n",
    "\n",
    "# Run the main scraper function\n",
    "raw_df = run_scraper()\n",
    "\n",
    "print(\"\\n‚úÖ Scraping Finished.\")\n",
    "display(raw_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3455534",
   "metadata": {},
   "source": [
    "# Run Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cd34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the preprocessor\n",
    "preprocessor = ReviewPreprocessor()\n",
    "\n",
    "# Run the process\n",
    "success = preprocessor.process()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n‚úÖ Preprocessing finished successfully!\")\n",
    "    df = preprocessor.df\n",
    "else:\n",
    "    print(\"‚ùå Preprocessing failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d918ab2",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 1. Ratings Distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='rating', data=df, palette='viridis')\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Star Rating')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# 2. Reviews per Bank\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='bank_code', data=df, palette='Set2')\n",
    "plt.title('Number of Reviews per Bank')\n",
    "plt.xlabel('Bank')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a268052",
   "metadata": {},
   "source": [
    "# Review Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ee4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='text_length', bins=50, kde=True, hue='bank_code')\n",
    "plt.title('Distribution of Review Lengths by Bank')\n",
    "plt.xlabel('Review Length (characters)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
